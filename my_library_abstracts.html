


<p><a name="Mohan2011b"></a>

<b>Shiwali Mohan</b> and John Laird.
 An Object-Oriented Approach to Reinforcement Learning in an
  Action Game.
 In <em>Proceedings of 7th the Artificial Intelligence for
  Interactive Digital Entertainment Conference</em>, AIIDE, 2011.
[&nbsp;<a href="my_library_bib.html#Mohan2011b">bib</a>&nbsp;| 
<a href="http://www.aaai.org/ocs/index.php/AIIDE/AIIDE11/paper/view/4069">http</a>&nbsp;| 
<a href="./content/mohan_aiide_2011.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
In this work, we look at the challenge of learning in an action game,Infinite Mario. Learning to play an action game can be divided intotwo distinct but related problems, learning an object-relatedbehavior and selecting a primitive action. We propose a framework that allows for the use of reinforcement learning for both ofthese problems. We present promising results in some instances of thegame and identify some problems that might affect learning.
</font></blockquote>
<p><blockquote><font size="-1">
Keywords: decision making; reinforcement learning; action games
</font></blockquote>

</p>

<p><a name="Mohan2011a"></a>

<b>Shiwali Mohan</b> and John Laird.
 Towards Situated, Interactive, Instructable Agents in a
  Cognitive Architecture.
 In <em>Papers from the 2011 AAAI Fall Symposium Series</em>, 2011.
[&nbsp;<a href="my_library_bib.html#Mohan2011a">bib</a>&nbsp;| 
<a href="http://www.aaai.org/ocs/index.php/FSS/FSS11/paper/view/4165">http</a>&nbsp;| 
<a href="./content/mohan_fss_2011.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
This paper discusses the challenge of designing instructable agents that can learn through interaction with a human expert. Learning through instruction is a powerful paradigm for acquiring knowledge because it limits the complexity of the learning task in a variety of ways. To support learning through instruction, the agent must be able to effectively communicate its lack of knowledge to the human, comprehend instructions, and apply them to the ongoing task. Weidentify some problems of concern when designing instructable agents. We propose an agent design that addresses some of these problems. We instantiate this design in the Soar cognitive architecture and analyze its capabilities on a learning task.
</font></blockquote>
<p><blockquote><font size="-1">
Keywords: cognition; Soar; learning with instruction; human agent collaboration; rule-based systems
</font></blockquote>

</p>

<p><a name="Mohan2010"></a>

<b>Shiwali Mohan</b> and John Laird.
 Relational Reinforcement Learning in Infinite Mario.
 In <em>Proceedings of the 24th AAAI Conference on Artificial
  Intelligence</em>, AAAI, 2010.
 <i>(Extended Abstract)</i>.
[&nbsp;<a href="my_library_bib.html#Mohan2010">bib</a>&nbsp;| 
<a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/view/1657">http</a>&nbsp;| 
<a href="./content/mohan.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
Relational representations in reinforcement learning allow for the use of structural information like the presence of objects and relationships between them in the description of value functions. Through this paper, we show that such representations allow for the inclusion of background knowledge that qualitatively describes a state and can be used to design agents that demonstrate learning behavior in domains with large state and actions spaces such as computer games.`
</font></blockquote>
<p>
</p>

<p><a name="Chatterjee2008"></a>

Niladri Chatterjee and <b>Shiwali Mohan</b>.
 Discovering Word Senses from Text using Random Indexing.
 In <em>Proceedings of the 9th International Conference on
  Computational linguistics and Intelligent Text Processing</em>, CICLing, 2008.
 <b>Best Paper Award</b>.
[&nbsp;<a href="my_library_bib.html#Chatterjee2008">bib</a>&nbsp;| 
<a href="http://www.springerlink.com/content/xp70kw14w0054541/">http</a>&nbsp;| 
<a href="http://www.springerlink.com/content/xp70kw14w0054541/fulltext.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
Random Indexing is a novel technique for dimensionality reduction while creating Word Space model from a given text. This paper explores the possible application of Random Indexing in discovering word senses from the text. The words appearing in the text are plotted onto a multi-dimensional Word Space using Random Indexing. The geometric distance between words is used as an indicative of their semantic similarity. Soft Clustering by Committee algorithm (CBC) has been used to constellate similar words. The present work shows that the Word Space model can be used effectively to determine the similarity index required for clustering. The approach does not require parsers, lexicons or any other resources which are traditionally used in sense disambiguation of words. The proposed approach has been applied to TASA corpus and encouraging results have been obtained.
</font></blockquote>
<p>
</p>

<p><a name="Mohan2007"></a>

Niladri Chatterjee and <b>Shiwali Mohan</b>.
 Extraction-Based Single-Document Summarization Using Random Indexing.
 ICTAI, 2007.
[&nbsp;<a href="my_library_bib.html#Mohan2007">bib</a>&nbsp;| 
<a href="http://www.computer.org.proxy.lib.umich.edu/portal/web/csdl/doi/10.1109/ICTAI.2007.28">http</a>&nbsp;| 
<a href="./content/mohan_ictai.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
This paper presents a summarization technique for text documents exploiting the semantic similarity between sentences to remove the redundancy from the text. Semantic similarity scores are computed by mapping the sentences on a semantic space using Random Indexing. Random Indexing, in comparison with other semantic space algorithms, presents a computationally efficient way of implicit dimensionality reduction. It involves inexpensive vector computations such as addition. It thus provides an efficient way to compute similarities between words, sentences and documents. Random Indexing has been used to compute the semantic similarity scores of sentences and graph-based ranking algorithms have been employed to produce an extract of the given text.
</font></blockquote>
<p>
</p><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.96.</em></p>
