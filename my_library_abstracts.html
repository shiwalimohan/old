


<p><a name="Mohan2007"></a>

Niladri Chatterjee and <b>Shiwali Mohan</b>.
 Extraction-based single-document summarization using random indexing.
 In <em>Proceeding of the 19th IEEE International Conference on Tools
  with Artificial Intelligence</em>, ICTAI, 2007.<br />
[&nbsp;<a href="my_library_bib.html#Mohan2007">bib</a>&nbsp;| 
<a href="http://www.computer.org.proxy.lib.umich.edu/portal/web/csdl/doi/10.1109/ICTAI.2007.28">http</a>&nbsp;| 
<a href="./content/mohan_ictai.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
This paper presents a summarization technique for text documents exploiting the semantic similarity between sentences to remove the redundancy from the text. Semantic similarity scores are computed by mapping the sentences on a semantic space using Random Indexing. Random Indexing, in comparison with other semantic space algorithms, presents a computationally efficient way of implicit dimensionality reduction. It involves inexpensive vector computations such as addition. It thus provides an efficient way to compute similarities between words, sentences and documents. Random Indexing has been used to compute the semantic similarity scores of sentences and graph-based ranking algorithms have been employed to produce an extract of the given text.
</font></blockquote>
<p>
</p>

<p><a name="Mohan2008"></a>

Niladri Chatterjee and <b>Shiwali Mohan</b>.
 Discovering word senses from text using random indexing.
 In <em>Proceedings of the 9th International Conference on
  Computational linguistics and Intelligent Text Processing</em>, CICLing, 2008.
 <b>Best Paper Award</b>.<br />
[&nbsp;<a href="my_library_bib.html#Mohan2008">bib</a>&nbsp;| 
<a href="http://www.springerlink.com/content/xp70kw14w0054541/">http</a>&nbsp;| 
<a href="http://www.springerlink.com/content/xp70kw14w0054541/fulltext.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
Random Indexing is a novel technique for dimensionality reduction while creating Word Space model from a given text. This paper explores the possible application of Random Indexing in discovering word senses from the text. The words appearing in the text are plotted onto a multi-dimensional Word Space using Random Indexing. The geometric distance between words is used as an indicative of their semantic similarity. Soft Clustering by Committee algorithm (CBC) has been used to constellate similar words. The present work shows that the Word Space model can be used effectively to determine the similarity index required for clustering. The approach does not require parsers, lexicons or any other resources which are traditionally used in sense disambiguation of words. The proposed approach has been applied to TASA corpus and encouraging results have been obtained.
</font></blockquote>
<p>
</p>

<p><a name="MohanML"></a>

<b>Shiwali Mohan</b>.
 Classification of executed and imagined motor movement eeg signals.
 December 2009.<br />
[&nbsp;<a href="my_library_bib.html#MohanML">bib</a>&nbsp;| 
<a href="http://www.eecs.umich.edu/~cscott/past_courses/eecs545f09/projects/MohanPillaiSleight.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
Electroencephalography (EEG), which contains cortical potentials during various mental processes, can be used to provide neural input signals to activate a brain machine interface (BMI). The eﬀectiveness of such an EEG-based prosthetic system would rely on correct classiﬁcation of executed motor signals from imagined motor movement signals; an executed motor signal should initiate movement in the artiﬁcial limb while signals from motor imagery should be ﬁltered out. This work evaluates the performance of features based on average EEG signal power contained in diﬀerent frequency bands in order to distinguish between the executed and imagined EEG signals. We also investigate Independent Component Analysis (ICA) as a scheme to remove irrelevant artifacts from the EEG signals. Results demonstrate that using EEG for classiﬁcation can be performed eﬀectively; however results vary signiﬁcantly from patient to patient suggesting that BMI must highly specialized for an individual patient.
</font></blockquote>
<p>
</p>

<p><a name="Mohan2010"></a>

<b>Shiwali Mohan</b> and John Laird.
 Relational reinforcement learning in infinite mario.
 In <em>Proceedings of the 24th AAAI Conference on Artificial
  Intelligence</em>, AAAI, 2010.
 <i>(Extended Abstract)</i>.<br />
[&nbsp;<a href="my_library_bib.html#Mohan2010">bib</a>&nbsp;| 
<a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/view/1657">http</a>&nbsp;| 
<a href="./content/mohan.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
Relational representations in reinforcement learning allow for the use of structural information like the presence of objects and relationships between them in the description of value functions. Through this paper, we show that such representations allow for the inclusion of background knowledge that qualitatively describes a state and can be used to design agents that demonstrate learning behavior in domains with large state and actions spaces such as computer games.`
</font></blockquote>
<p>
</p>

<p><a name="Mohan2011b"></a>

<b>Shiwali Mohan</b> and John Laird.
 An Object-Oriented approach to reinforcement learning in an
  action game.
 In <em>Proceedings of 7th the Artificial Intelligence for
  Interactive Digital Entertainment Conference</em>, AIIDE, 2011.<br />
[&nbsp;<a href="my_library_bib.html#Mohan2011b">bib</a>&nbsp;| 
<a href="http://www.aaai.org/ocs/index.php/AIIDE/AIIDE11/paper/view/4069">http</a>&nbsp;| 
<a href="./content/mohan_aiide_2011.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
In this work, we look at the challenge of learning in an action game,Infinite Mario. Learning to play an action game can be divided intotwo distinct but related problems, learning an object-relatedbehavior and selecting a primitive action. We propose a framework that allows for the use of reinforcement learning for both ofthese problems. We present promising results in some instances of thegame and identify some problems that might affect learning.
</font></blockquote>
<p><blockquote><font size="-1">
Keywords: decision making; reinforcement learning; action games
</font></blockquote>

</p>

<p><a name="Mohan2011a"></a>

<b>Shiwali Mohan</b> and John Laird.
 Towards situated, Interactive, Instructable Agents in a
  Cognitive Architecture.
 In <em>Papers from the 2011 AAAI Fall Symposium Series</em>, 2011.<br />
[&nbsp;<a href="my_library_bib.html#Mohan2011a">bib</a>&nbsp;| 
<a href="http://www.aaai.org/ocs/index.php/FSS/FSS11/paper/view/4165">http</a>&nbsp;| 
<a href="./content/mohan_fss_2011.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
This paper discusses the challenge of designing instructable agents that can learn through interaction with a human expert. Learning through instruction is a powerful paradigm for acquiring knowledge because it limits the complexity of the learning task in a variety of ways. To support learning through instruction, the agent must be able to effectively communicate its lack of knowledge to the human, comprehend instructions, and apply them to the ongoing task. Weidentify some problems of concern when designing instructable agents. We propose an agent design that addresses some of these problems. We instantiate this design in the Soar cognitive architecture and analyze its capabilities on a learning task.
</font></blockquote>
<p><blockquote><font size="-1">
Keywords: cognition; Soar; learning with instruction; human agent collaboration; rule-based systems
</font></blockquote>

</p>

<p><a name="Mohan2009"></a>

<b>Shiwali Mohan</b> and John&nbsp;E. Laird.
 Learning to play mario.
 Technical Report CCA-TR-2009-03, Center for Cognitive Architecture,
  University of Michigan, Ann Arbor, Michigan, 2009.<br />
[&nbsp;<a href="my_library_bib.html#Mohan2009">bib</a>&nbsp;| 
<a href="http://sitemaker.umich.edu/SoarWeb/Publications/da.data/000000000000000000000000000000000000000003005536/Downloadpaper/filename">http</a>&nbsp;]
<blockquote><font size="-1">
Computer Games are interesting test beds for research in Artificial Intelligence and Machine Learning. Games usually have continuous state spaces, large action spaces and  are characterized by complex relationships between components. Without applying abstraction and generalizations, learning in computer games domain becomes infeasible. Through this work, we investigate some designs that facilitate tractable reinforcement learning in symbolic agents developed using Soar architecture operating in a complex domain, Infinite Mario. Object oriented representations of the environment greatly simplify otherwise complex state spaces. We also demonstrate that imposing hierarchy in problem structure greatly reduces the complexity of the tasks and aids in learning generalized policies that can be transferred across similar tasks.
</font></blockquote>
<p>
</p>